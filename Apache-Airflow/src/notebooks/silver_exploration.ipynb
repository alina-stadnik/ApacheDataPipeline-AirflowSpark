{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extraindo interações**\n",
    "\n",
    "**Objetivo**: unir os valores relacionados a data em que os tweets foram postados para criar um relatório que seja possível visualizar o desempenho da palavra \"data science\" nos Tweets, como, por exemplo, a quantidade de comentários sobre o tema ao longo da semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"twitter_silver\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "parent_folder = \"../../datalake/Silver/twitter_datascience/tweet\"\n",
    "subfolders = [os.path.join(parent_folder, folder) for folder in os.listdir(parent_folder) if os.path.isdir(os.path.join(parent_folder, folder))]\n",
    "\n",
    "df_tweet = spark.read.json(subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- conversation_id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- like_count: long (nullable = true)\n",
      " |-- quote_count: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tweet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "|author_id|conversation_id|          created_at| id|like_count|quote_count|reply_count|retweet_count|                text|\n",
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "|       84|             92|2024-07-03T08:58:...| 61|        27|         85|         95|          100|Tweet fictício ge...|\n",
      "|       61|             20|2024-07-03T17:51:...| 74|        72|         44|         61|           51|Tweet fictício ge...|\n",
      "|       54|             71|2024-07-03T19:12:...|  1|        39|         94|         31|           49|Este é um tweet f...|\n",
      "|       20|             89|2024-07-03T14:58:...|  4|        39|         37|         74|           97|Tweet fictício cr...|\n",
      "|        8|             36|2024-07-03T06:51:...| 24|        22|          0|         89|           48|Um terceiro tweet...|\n",
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tweet.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novo dataframe para elaborar o relatório\n",
    "\n",
    "# Etapa 1: agrupar as informações\n",
    "# groupby unindo pela coluna de data (coluna 'created_at')\n",
    "# primeiro functions: transforma para um valor de data e cria um apelido/novo nome para a coluna\n",
    "tweet_conversas = df_tweet.alias(\"tweet\")\\\n",
    "        .groupBy(f.to_date(\"created_at\").alias(\"created_date\"))\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2: agregar informações/unir os dados\n",
    "# agg: como vai agregar os dados e criar novas colunas\n",
    "# primeira info: quantas pessoas distintas estão fazendo tweets em relação aquele assunto\n",
    "# para isso usa a coluna de author_id que identifica de maneira única os autores \n",
    "# se contar apenas os ids terá apenas o número de tweets, logo precisa ser de uma maneira específica/única - countDistinct\n",
    "# tb coloca o nome que quer para essa coluna\n",
    "tweet_conversas = df_tweet.alias(\"tweet\")\\\n",
    "        .groupBy(f.to_date(\"created_at\").alias(\"created_date\"))\\\n",
    "        .agg(\n",
    "            f.countDistinct(\"author_id\").alias(\"n_tweets\"))\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outras infos são relacionadas a uma contagem que já existem (likes, quotes, replies, retweets) SÓ QUE POR DATAS\n",
    "# necessário somar todas as que aconteceram na mesma data - sum\n",
    "\n",
    "tweet_conversas = df_tweet.alias(\"tweet\")\\\n",
    "        .groupBy(f.to_date(\"created_at\").alias(\"created_date\"))\\\n",
    "        .agg(\n",
    "            f.countDistinct(\"author_id\").alias(\"n_tweets\"),\n",
    "            f.sum(\"like_count\").alias(\"n_like\"),\n",
    "            f.sum(\"quote_count\").alias(\"n_quote\"),\n",
    "            f.sum(\"reply_count\").alias(\"n_reply\"),\n",
    "            f.sum(\"retweet_count\").alias(\"n_retweet\"))\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é relevante saber que dia da semana que aconteceramas ocorrencias\n",
    "# para isso usa withColumn(\"weekday\") pq quer saber o dia da semana\n",
    "# f.date_format para formatar uma data (que é o created_date)\n",
    "# o \"E\" indica que queremos os dias da semana\n",
    "tweet_conversas = df_tweet.alias(\"tweet\")\\\n",
    "        .groupBy(f.to_date(\"created_at\").alias(\"created_date\"))\\\n",
    "        .agg(\n",
    "            f.countDistinct(\"author_id\").alias(\"n_tweets\"),\n",
    "            f.sum(\"like_count\").alias(\"n_like\"),\n",
    "            f.sum(\"quote_count\").alias(\"n_quote\"),\n",
    "            f.sum(\"reply_count\").alias(\"n_reply\"),\n",
    "            f.sum(\"retweet_count\").alias(\"n_retweet\")\n",
    "        ).withColumn(\"weekday\", f.date_format(\"created_date\", \"E\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------+-------+-------+---------+-------+\n",
      "|created_date|n_tweets|n_like|n_quote|n_reply|n_retweet|weekday|\n",
      "+------------+--------+------+-------+-------+---------+-------+\n",
      "|  2024-05-30|      10|   497|    408|    436|      583|    Thu|\n",
      "|  2024-05-29|       9|   534|    581|    428|      474|    Wed|\n",
      "|  2024-06-02|      45|  2823|   2780|   3366|     3050|    Sun|\n",
      "|  2024-07-02|      16|  1186|   1283|    971|     1141|    Tue|\n",
      "|  2024-05-31|      18|   920|    943|   1152|      875|    Fri|\n",
      "+------------+--------+------+-------+-------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_conversas.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Próximo passo é transformar esse jupyter em um .py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
